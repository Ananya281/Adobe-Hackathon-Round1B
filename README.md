# Adobe Hackathon Round 1B â€“ Intelligent Document Analyzer

A smart, Dockerized Python solution that mimics an intelligent document analyst. This tool extracts persona-driven insights from a collection of documents based on a specific job role and job-to-be-done query, enabling content filtering, summarization, and persona alignment.

---

## âœ¨ Features

- ğŸ§  Understands the persona and intent (job-to-be-done)
- ğŸ“„ Processes multiple PDFs at once
- ğŸ” Performs semantic filtering, clustering, and highlighting of relevant sections
- ğŸ“¦ Generates clean and structured JSON output
- ğŸ³ Docker-ready, no setup hassle
- ğŸ”’ Fully offline â€” No internet or GPU required

---

## ğŸ› ï¸ Tech Stack

| ğŸ”§ Component     | ğŸš€ Technology         |
|------------------|------------------------|
| Language         | Python 3.10            |
| PDF Processing     | `pdfminer.six`, `PyMuPDF`         |
| NLP & AI       | `spaCy`, `transformers`, `scikit-learn`|
| Numerical Ops    | `Pandas`,`NumPy`                |
| Containerization | Docker                 |
| Architecture     | `linux/amd64 (x86_64)` |

---

## ğŸ“ Project Structure

```
Adobe-Hackathon-Round1B/
â”œâ”€â”€ Dockerfile                # Docker configuration
â”œâ”€â”€ main.py                   # Main processing script
â”œâ”€â”€ requirements.txt          # Python dependencies
â”œâ”€â”€ README.md                 # Project documentation
â””â”€â”€ sample_dataset/
    â”œâ”€â”€ input/
    â”‚   â”œâ”€â”€ collection/       # Place all input PDFs here
    â”‚   â””â”€â”€ input.json        # Persona query file (must be named exactly this)
    â””â”€â”€ output/
        â””â”€â”€ output.json       # Auto-generated output file
```

---

## ğŸš€ How to Run with Docker

Make sure Docker is installed and running.

#### â–¶ï¸ Step 1: Build the Docker Image

```
docker build --platform linux/amd64 -t adobe-hackathon-round1b .
```


#### â–¶ï¸ Step 2: Run the Container

```
docker run -v "$(pwd):/app" adobe-hackathon-round1b
```

Note:- for Windows users (Git Bash):
If you're running the Docker command on Windows using Git Bash or MSYS2, please add `winpty` before `docker run` to avoid TTY-related issues.

- ğŸ“¥ Input PDFs: `sample_dataset/input/collection/`

- ğŸ§‘â€ğŸ’¼ Persona Query File: `sample_dataset/input/input.json` (must be named `input.json`)

- ğŸ“¤ Output: `sample_dataset/output/result.json`

- ğŸ”’ Network: Fully disabled (offline and secure)

## ğŸ“„ Input Format

ğŸ¯ Persona Input (input.json)

```
{
  "persona": "Academic Researcher",
  "job_to_be_done": "Research on latest methods for citation-based ranking"
}
```

- `"persona"`: Describes the role/user type (e.g., "Student", "Analyst", "Professor")

- `"job_to_be_done"`: Describes what they hope to accomplish using the document

## âœ… Output Format

```
The system produces a structured JSON with:

{
  "metadata": { ... },
  "matched_documents": [
    {
      "title": "Document Title",
      "relevance_score": 0.91,
      "summary": "This document discusses...",
      "highlights": ["Key sentence 1", "Key sentence 2"]
    },
    ...
  ],
  "extracted_topics": ["topic1", "topic2"]
}
```

Output file is saved at:

```
sample_dataset/output/result.json
```

---

## ğŸ“¬ Deliverables

- ğŸ§¾ result.json (final output)

- ğŸ“ approach_explanation.md (500â€“600 words) explaining:

    - Persona mapping logic
    - Clustering/filtering approach
    - Model or rule-based strategy used

- âš™ï¸ Execution instructions (this README)

---

## ğŸš« Constraints

- Max: 10 documents

- Execution time: â±ï¸ <5 mins

- No internet access during container execution

---

## ğŸ§ª Sample Input for Testing

You can refer to the provided PDF and persona samples in the `sample_dataset/input/collection/` directory and test with a variety of roles like:

- ğŸ‘©â€ğŸ« Academic Researcher

- ğŸ“Š Business Analyst

- ğŸ‘¨â€ğŸ“ Undergraduate Student
